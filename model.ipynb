{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = np.genfromtxt('magic04.data', delimiter=',', dtype=str) # Data is in the form of array of tuples\n",
    "labels = data_set[:, len(data_set[0]) - 1:len(data_set[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sampler = RandomUnderSampler()\n",
    "sampled_data, sampled_labels = under_sampler.fit_resample(data_set, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'g': 12332, 'h': 6688}\n",
      "{'g': 6688, 'h': 6688}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(sampled_labels, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_set, testing_data_set = train_test_split(data_set, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.array(training_data_set[:, 0:len(training_data_set[0]) - 1]).astype(np.float64)\n",
    "training_labels = training_data_set[:, len(training_data_set[0]) - 1:len(training_data_set[0])]\n",
    "training_labels = np.reshape(training_labels, len(training_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = np.array(testing_data_set[:, 0:len(testing_data_set[0]) - 1]).astype(np.float64)\n",
    "testing_labels = testing_data_set[:, len(testing_data_set[0]) - 1:len(testing_data_set[0])]\n",
    "testing_labels = np.reshape(testing_labels, len(testing_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(tr_data, tr_labels, tst_data):\n",
    "    decision_tree = tree.DecisionTreeClassifier()\n",
    "    decision_tree_pred = decision_tree.fit(tr_data, tr_labels).predict(tst_data)\n",
    "    return decision_tree_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_boost(tr_data, tr_labels, tst_data, n_estimators):\n",
    "    ada_boost = AdaBoostClassifier(n_estimators=n_estimators)\n",
    "    ada_boost_pred = ada_boost.fit(tr_data, tr_labels).predict(tst_data)\n",
    "    return ada_boost_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) K-Nearest Neighbors (K-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(tr_data, tr_labels, tst_data, k_neighb = 3):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k_neighb)\n",
    "    knn_pred = neigh.fit(tr_data, tr_labels).predict(tst_data)\n",
    "    return knn_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Random Forests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forests(tr_data, tr_labels, tst_data, n_estimators):\n",
    "    random_forests = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    random_forests_pred = random_forests.fit(tr_data, tr_labels).predict(tst_data)\n",
    "    return random_forests_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Na¨ıve Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(tr_data, tr_labels, tst_data):\n",
    "    gnb = GaussianNB()\n",
    "    naive_bayes_pred = gnb.fit(tr_data, tr_labels).predict(tst_data)\n",
    "    return naive_bayes_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Parameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree accuracy:  81.23028391167192 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81274406762659"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_pred = decision_tree(training_data, training_labels, testing_data)\n",
    "print(\"Decision tree accuracy: \", accuracy_score(testing_labels, decision_tree_pred) * 100, \"%\")\n",
    "precision_score(testing_labels, decision_tree_pred, average='weighted')\n",
    "recall_score(testing_labels, decision_tree_pred, average='weighted')\n",
    "f1_score(testing_labels, decision_tree_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na¨ıve bayes accuracy:  73.39642481598318 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7089796754098223"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes_pred = naive_bayes(training_data, training_labels, testing_data)\n",
    "print(\"Na¨ıve bayes accuracy: \", accuracy_score(testing_labels, naive_bayes_pred) * 100, \"%\")\n",
    "precision_score(testing_labels, naive_bayes_pred, average='weighted')\n",
    "recall_score(testing_labels, naive_bayes_pred, average='weighted')\n",
    "f1_score(testing_labels, naive_bayes_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-NN accuracy:  77.40974412898703 %\n",
      "2-NN accuracy:  78.61899754644234 %\n",
      "3-NN accuracy:  79.56536978618998 %\n",
      "4-NN accuracy:  79.70557308096741 %\n",
      "5-NN accuracy:  80.354013319313 %\n",
      "6-NN accuracy:  80.21381002453558 %\n",
      "7-NN accuracy:  80.61689449702068 %\n",
      "8-NN accuracy:  80.30143708377146 %\n",
      "9-NN accuracy:  80.354013319313 %\n",
      "10-NN accuracy:  80.63441990886786 %\n",
      "11-NN accuracy:  80.51174202593761 %\n",
      "12-NN accuracy:  80.58184367332632 %\n",
      "13-NN accuracy:  80.51174202593761 %\n",
      "14-NN accuracy:  80.45916579039607 %\n",
      "15-NN accuracy:  80.87977567472836 %\n",
      "16-NN accuracy:  80.65194532071503 %\n",
      "17-NN accuracy:  80.5993690851735 %\n",
      "18-NN accuracy:  80.61689449702068 %\n",
      "19-NN accuracy:  80.82719943918683 %\n",
      "20-NN accuracy:  80.58184367332632 %\n"
     ]
    }
   ],
   "source": [
    "k_neighb = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "for k in k_neighb:\n",
    "    knn_pred = knn(training_data, training_labels, testing_data, k)\n",
    "    print(str(k) + \"-NN accuracy: \", accuracy_score(testing_labels, knn_pred) * 100, \"%\")\n",
    "    precision_score(testing_labels, knn_pred, average='weighted')\n",
    "    recall_score(testing_labels, knn_pred, average='weighted')\n",
    "    f1_score(testing_labels, knn_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90_estimators AdaBoost accuracy:  84.13950227830354 %\n",
      "91_estimators AdaBoost accuracy:  84.24465474938661 %\n",
      "92_estimators AdaBoost accuracy:  84.22712933753942 %\n",
      "93_estimators AdaBoost accuracy:  84.22712933753942 %\n",
      "94_estimators AdaBoost accuracy:  84.24465474938661 %\n",
      "95_estimators AdaBoost accuracy:  84.20960392569225 %\n",
      "96_estimators AdaBoost accuracy:  84.3322818086225 %\n",
      "97_estimators AdaBoost accuracy:  84.27970557308096 %\n",
      "98_estimators AdaBoost accuracy:  84.24465474938661 %\n",
      "99_estimators AdaBoost accuracy:  84.3322818086225 %\n",
      "100_estimators AdaBoost accuracy:  84.43743427970557 %\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
    "for n in n_estimators:\n",
    "    ada_boost_pred = ada_boost(training_data, training_labels, testing_data, n)\n",
    "    print(str(n) + \"_estimators AdaBoost accuracy: \", accuracy_score(testing_labels, ada_boost_pred) * 100, \"%\")\n",
    "    precision_score(testing_labels, ada_boost_pred, average='weighted')\n",
    "    recall_score(testing_labels, ada_boost_pred, average='weighted')\n",
    "    f1_score(testing_labels, ada_boost_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90_estimators random forests accuracy:  87.34665264633719 %\n",
      "91_estimators random forests accuracy:  87.76726253066947 %\n",
      "92_estimators random forests accuracy:  87.60953382404486 %\n",
      "93_estimators random forests accuracy:  87.34665264633719 %\n",
      "94_estimators random forests accuracy:  87.59200841219769 %\n",
      "95_estimators random forests accuracy:  87.78478794251666 %\n",
      "96_estimators random forests accuracy:  87.6621100595864 %\n",
      "97_estimators random forests accuracy:  87.59200841219769 %\n",
      "98_estimators random forests accuracy:  87.62705923589205 %\n",
      "99_estimators random forests accuracy:  87.78478794251666 %\n",
      "100_estimators random forests accuracy:  87.78478794251666 %\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
    "for n in n_estimators:\n",
    "    random_forests_pred = random_forests(training_data, training_labels, testing_data, n)\n",
    "    print(str(n) + \"_estimators random forests accuracy: \", accuracy_score(testing_labels, random_forests_pred) * 100, \"%\")\n",
    "    precision_score(testing_labels, random_forests_pred, average='weighted')\n",
    "    recall_score(testing_labels, random_forests_pred, average='weighted')\n",
    "    f1_score(testing_labels, random_forests_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Report Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "training_encoded_labels = le.fit_transform(training_labels)\n",
    "testing_encoded_labels = le.fit_transform(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape (13314, 10)\n",
      "Training Label Shape (13314,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Data Shape {training_data.shape}')\n",
    "print(f'Training Label Shape {training_encoded_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data  [ 54.2122  14.3806   2.8388   0.3594   0.2239 -49.5198 -37.021    6.2357\n",
      "  28.641  110.78  ]\n",
      "Training Label 1\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Data  {training_data[0]}')\n",
    "print(f'Training Label {training_encoded_labels[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_t = torch.from_numpy(training_data).float()\n",
    "testing_data_t = torch.from_numpy(testing_data).float()\n",
    "training_labels_t = torch.from_numpy(training_encoded_labels).float()\n",
    "testing_labels_t = torch.from_numpy(testing_encoded_labels).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13314, 10])\n",
      "torch.Size([5706, 10])\n"
     ]
    }
   ],
   "source": [
    "print(training_data_t.shape)\n",
    "print(testing_data_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5706,)\n",
      "(5706,)\n"
     ]
    }
   ],
   "source": [
    "print(testing_encoded_labels.shape)\n",
    "print(testing_encoded_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, input_layer, hidden_layer, output_layer):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.l1 = nn.Linear(input_layer, hidden_layer)\n",
    "        self.l2 = nn.Linear(hidden_layer, output_layer)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    " \n",
    "    def forward(self, data):\n",
    "        x = self.l1(data)\n",
    "        x = torch.relu(x)\n",
    "        x = self.l2(x)\n",
    "        return torch.sigmoid(x)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def train_evalute_model(model, epochs, optimizer, loss):\n",
    "#     epochs_data = []\n",
    "#     test_acc = 0.0\n",
    "#     for epoch in range(epochs):\n",
    "        # # X is a torch Variable\n",
    "        # permutation = torch.randperm(training_data.size()[0])\n",
    "\n",
    "        # for i in range(0,training_data.size()[0], batch_size):\n",
    "            # optimizer.zero_grad()\n",
    "\n",
    "            # indices = permutation[i:i+batch_size]\n",
    "            # batch_x, batch_y = training_data[indices], training_encoded_labels[indices]\n",
    "\n",
    "            # in case you wanted a semi-full example\n",
    "            # outputs = model.forward(batch_x)\n",
    "            # loss = loss(outputs, batch_y)\n",
    "\n",
    "            # loss.backward()\n",
    "            # optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_evalute_model(model, epochs, optimizer, loss_fn, training_data_t, testing_data_t, training_labels, testing_labels):\n",
    "    epochs_data = []\n",
    "    test_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        y_pred = model(training_data_t)\n",
    "        loss_train = loss_fn(y_pred, training_labels.reshape(-1, 1))\n",
    "        loss_train.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        y_pred_test = model(testing_data_t)\n",
    "        loss_test = loss_fn(y_pred_test, testing_labels)\n",
    "        condition = y_pred_test >= 0.5\n",
    "        y_pred_test = torch.where(condition, 1, 0)\n",
    "        test_acc = torch.sum(y_pred_test == testing_labels) / len(testing_labels)\n",
    "        epochs_data.append(test_acc)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'EPOCH {epoch} : Test loss {loss_test} --- Test Acc is {test_acc}')\n",
    "    return epochs_data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationModel(10, 64, 1)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 62.90485763549805 --- Test Acc is 0.34121978282928467\n",
      "Test loss 42.22859573364258 --- Test Acc is 0.3391167223453522\n",
      "Test loss 1.5627436637878418 --- Test Acc is 0.6154924631118774\n",
      "Test loss 0.9155380129814148 --- Test Acc is 0.6640378832817078\n",
      "Test loss 0.6877080202102661 --- Test Acc is 0.7004907131195068\n",
      "Test loss 0.6104406714439392 --- Test Acc is 0.7267788052558899\n",
      "Test loss 0.5660296678543091 --- Test Acc is 0.7395724058151245\n",
      "Test loss 0.5375896692276001 --- Test Acc is 0.7492113709449768\n",
      "Test loss 0.5193892121315002 --- Test Acc is 0.7562215328216553\n",
      "Test loss 0.5068076252937317 --- Test Acc is 0.7625306844711304\n",
      "Test loss 0.4978850483894348 --- Test Acc is 0.7667367458343506\n",
      "Test loss 0.4915832579135895 --- Test Acc is 0.772870659828186\n",
      "Test loss 0.4866025447845459 --- Test Acc is 0.7744479775428772\n",
      "Test loss 0.4824337661266327 --- Test Acc is 0.7744479775428772\n",
      "Test loss 0.4786672592163086 --- Test Acc is 0.7760252356529236\n"
     ]
    }
   ],
   "source": [
    "acc = train_evalute_model(model, 1500, optimizer, loss_fn, training_data_t, testing_data_t, training_labels_t.reshape(-1, 1), testing_labels_t.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "384275cc682b8282d78d926a1c30ea86f5d409f6a82816c5f6672e2be770768b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
