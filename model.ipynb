{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = np.genfromtxt('magic04.data', delimiter=',', dtype=str) # Data is in the form of array of tuples\n",
    "labels = data_set[:, len(data_set[0]) - 1:len(data_set[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sampler = RandomUnderSampler()\n",
    "sampled_data, sampled_labels = under_sampler.fit_resample(data_set, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'g': 12332, 'h': 6688}\n",
      "{'g': 6688, 'h': 6688}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(sampled_labels, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_set, testing_data_set = train_test_split(data_set, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.array(training_data_set[:, 0:len(training_data_set[0]) - 1]).astype(np.float64)\n",
    "training_labels = training_data_set[:, len(training_data_set[0]) - 1:len(training_data_set[0])]\n",
    "training_labels = np.reshape(training_labels, len(training_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = np.array(testing_data_set[:, 0:len(testing_data_set[0]) - 1]).astype(np.float64)\n",
    "testing_labels = testing_data_set[:, len(testing_data_set[0]) - 1:len(testing_data_set[0])]\n",
    "testing_labels = np.reshape(testing_labels, len(testing_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(tr_data, tr_labels, tst_data):\n",
    "    decision_tree = tree.DecisionTreeClassifier()\n",
    "    decision_tree_pred = decision_tree.fit(tr_data, tr_labels).predict(tst_data)\n",
    "    return decision_tree_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_boost(tr_data, tr_labels, tst_data, n_estimators):\n",
    "    ada_boost = AdaBoostClassifier(n_estimators=n_estimators)\n",
    "    ada_boost_pred = ada_boost.fit(tr_data, tr_labels).predict(tst_data)\n",
    "    return ada_boost_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) K-Nearest Neighbors (K-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(tr_data, tr_labels, tst_data, k_neighb = 3):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k_neighb)\n",
    "    knn_pred = neigh.fit(tr_data, tr_labels).predict(tst_data)\n",
    "    return knn_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Random Forests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forests(tr_data, tr_labels, tst_data, n_estimators):\n",
    "    random_forests = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    random_forests_pred = random_forests.fit(tr_data, tr_labels).predict(tst_data)\n",
    "    return random_forests_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Na¨ıve Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(tr_data, tr_labels, tst_data):\n",
    "    gnb = GaussianNB()\n",
    "    naive_bayes_pred = gnb.fit(tr_data, tr_labels).predict(tst_data)\n",
    "    return naive_bayes_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Parameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree accuracy:  81.77357167893446 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8173872838925176"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_pred = decision_tree(training_data, training_labels, testing_data)\n",
    "print(\"Decision tree accuracy: \", accuracy_score(testing_labels, decision_tree_pred) * 100, \"%\")\n",
    "precision_score(testing_labels, decision_tree_pred, average='weighted')\n",
    "recall_score(testing_labels, decision_tree_pred, average='weighted')\n",
    "f1_score(testing_labels, decision_tree_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na¨ıve bayes accuracy:  72.94076410795654 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7037757415954962"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes_pred = naive_bayes(training_data, training_labels, testing_data)\n",
    "print(\"Na¨ıve bayes accuracy: \", accuracy_score(testing_labels, naive_bayes_pred) * 100, \"%\")\n",
    "precision_score(testing_labels, naive_bayes_pred, average='weighted')\n",
    "recall_score(testing_labels, naive_bayes_pred, average='weighted')\n",
    "f1_score(testing_labels, naive_bayes_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-NN accuracy:  78.42621801612339 %\n",
      "2-NN accuracy:  79.21486154924641 %\n",
      "3-NN accuracy:  79.67052225727305 %\n",
      "4-NN accuracy:  79.96845425867508 %\n",
      "5-NN accuracy:  80.354013319313 %\n",
      "6-NN accuracy:  80.5292674377848 %\n",
      "7-NN accuracy:  81.19523308797757 %\n",
      "8-NN accuracy:  81.45811426568524 %\n",
      "9-NN accuracy:  81.61584297230985 %\n",
      "10-NN accuracy:  81.44058885383807 %\n",
      "11-NN accuracy:  81.61584297230985 %\n",
      "12-NN accuracy:  81.31791097090782 %\n",
      "13-NN accuracy:  81.4055380301437 %\n",
      "14-NN accuracy:  81.35296179460218 %\n",
      "15-NN accuracy:  81.44058885383807 %\n",
      "16-NN accuracy:  81.10760602874167 %\n",
      "17-NN accuracy:  81.66841920785139 %\n",
      "18-NN accuracy:  81.17770767613038 %\n",
      "19-NN accuracy:  81.44058885383807 %\n",
      "20-NN accuracy:  81.16018226428321 %\n"
     ]
    }
   ],
   "source": [
    "k_neighb = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "for k in k_neighb:\n",
    "    knn_pred = knn(training_data, training_labels, testing_data, k)\n",
    "    print(str(k) + \"-NN accuracy: \", accuracy_score(testing_labels, knn_pred) * 100, \"%\")\n",
    "    precision_score(testing_labels, knn_pred, average='weighted')\n",
    "    recall_score(testing_labels, knn_pred, average='weighted')\n",
    "    f1_score(testing_labels, knn_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90_estimators AdaBoost accuracy:  84.43743427970557 %\n",
      "91_estimators AdaBoost accuracy:  84.45495969155276 %\n",
      "92_estimators AdaBoost accuracy:  84.4199088678584 %\n",
      "93_estimators AdaBoost accuracy:  84.43743427970557 %\n",
      "94_estimators AdaBoost accuracy:  84.40238345601122 %\n",
      "95_estimators AdaBoost accuracy:  84.61268839817735 %\n",
      "96_estimators AdaBoost accuracy:  84.5075359270943 %\n",
      "97_estimators AdaBoost accuracy:  84.54258675078864 %\n",
      "98_estimators AdaBoost accuracy:  84.54258675078864 %\n",
      "99_estimators AdaBoost accuracy:  84.54258675078864 %\n",
      "100_estimators AdaBoost accuracy:  84.5075359270943 %\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
    "for n in n_estimators:\n",
    "    ada_boost_pred = ada_boost(training_data, training_labels, testing_data, n)\n",
    "    print(str(n) + \"_estimators AdaBoost accuracy: \", accuracy_score(testing_labels, ada_boost_pred) * 100, \"%\")\n",
    "    precision_score(testing_labels, ada_boost_pred, average='weighted')\n",
    "    recall_score(testing_labels, ada_boost_pred, average='weighted')\n",
    "    f1_score(testing_labels, ada_boost_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90_estimators random forests accuracy:  87.45180511742025 %\n",
      "91_estimators random forests accuracy:  87.48685594111461 %\n",
      "92_estimators random forests accuracy:  87.45180511742025 %\n",
      "93_estimators random forests accuracy:  87.32912723449002 %\n",
      "94_estimators random forests accuracy:  87.45180511742025 %\n",
      "95_estimators random forests accuracy:  87.55695758850332 %\n",
      "96_estimators random forests accuracy:  87.73221170697512 %\n",
      "97_estimators random forests accuracy:  87.46933052926744 %\n",
      "98_estimators random forests accuracy:  87.67963547143358 %\n",
      "99_estimators random forests accuracy:  87.57448300035051 %\n",
      "100_estimators random forests accuracy:  87.73221170697512 %\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
    "for n in n_estimators:\n",
    "    random_forests_pred = random_forests(training_data, training_labels, testing_data, n)\n",
    "    print(str(n) + \"_estimators random forests accuracy: \", accuracy_score(testing_labels, random_forests_pred) * 100, \"%\")\n",
    "    precision_score(testing_labels, random_forests_pred, average='weighted')\n",
    "    recall_score(testing_labels, random_forests_pred, average='weighted')\n",
    "    f1_score(testing_labels, random_forests_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Report Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "384275cc682b8282d78d926a1c30ea86f5d409f6a82816c5f6672e2be770768b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
